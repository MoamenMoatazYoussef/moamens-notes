# Algorithms course
## What are algorithms and why should we learn them
Have you ever played a strategy game? Red Alert 2, StarCraft and StarCraft 2, WarCraft 3, Age of Empires 1 and 2, Empire Earth, Crusaders 2 and 3, Command & Conquer 3, all of these are strategy games and I love strategy games <3.

When you start a game, you begin with a *base* and some *units* under your command. The objective is to defeat the enemy by destroying the enemy's base and killing all of their units. 
- To reach this objective, you need to build an army.
- To build the army, you need to create warrior units.
- To create warrior units, you need *resources* to build the units, and *resources* to build the buildings that create the units.
- To get *resources*, you need builder units to mine the resources.
- To mine the *resources*, you need special buildings.

In my opinion as a long-time strategy game fan, the key to win or lose in a strategy game is all the decisions involving *getting and using resources*:
- If you use one builder unit to mine resources to focus on creating warriors, you won't get enough warriors or even defend the base from enemy warriors in time.
- If you use all of your resources to make builders to mine more resources, you won't build the defences or the army you need to defend yourself and defeat the enemy.
- If you: 
    + use all your resources to make builders to mine resources *for some time*, then
    + gradually stop producing builders and take some of existing builders to start building *defences* and maintain them, then 
    + focus on mining resources and finally building the army
You'll have a higher probability to win than the other two scenarios.

In all scenarios, you had the same resources at the start, and the same time, **what caused the third one to win?** <br/>

In the third scenario, we didn't just use our resources, we were smart in using them, we used them *efficiently*.

In computer science, we play a giant strategy game:
- The objective is to make the app *work* and satisfy the *user*.
- To make the app work and satisfy the user, your program must *run in a convenient* way for the user.
- To do that, your app shouldn't interrupt other apps, and should not make the user wait.
- To not interrupt other apps, your app should use the least ***memory*** it can use.
- To not make the user wait, your app should be as *fast* as possible.
- To make it fast, we must do steps that take the least amount of ***CPU clock cycles***.

The ***memory*** and ***CPU clock cycles*** are your resources. And we must use these resources *efficiently*:

*Efficient* in CS means:
- Uses the minimum memory.
- Takes the least time.

When we encounter a problem in CS, we may be able to come up with a simple solution to it.

This solution consists of steps, these steps, grouped together, are called an ***Algorithm***.

In CS, we encounter common problems, and for these common problems a lot of solutions (or ***algorithms***) are developed.

Some of these solutions are *better* than others. What does it mean to have a solution that's better than another, don't they solve problems anyway?

We use ***algorithms*** and ***algorithmic thinking*** to:
- Come up with solutions for problems.
- Try molding and tweaking our initial solution to come up with a more *efficient* solution.

**So the real benefit of learning algorithms and algorithmic thinking is** <br/>
- When you learn to *think in an algorithmic way*, you are more able to come up with solutions and make them *efficient*.
- When you learn *some existing common algorithms*, you become more aware of the possible *solutions and use cases* of a given problem.

That is the power of algorithms. <br/>
You won't develop a sorting algorithm more efficient than mergesort. You won't encounter that many problems that require hard algorithmic approaches, but:
- You will be **aware** of the common use cases out there, you will know how things work and will be able to **think in terms of algorithms**.
- You will also be able to **match some use cases you encounter with common algorithmic problems**, which gives you a starting point to think about solving your own use case.
- Finally, you will be able to **estimate the best possible resource usage of your problem**, because you know understand how to think in terms of algorithms, you know what can be tweaked and what won't. 

***Note from Moamen:*** Most of the problems you encounter in web development according to my experience are design problems, not algorithmic problems, but knowing algorithms helped me organize my thoughts in solving design problems, as well as some algorithmic problem that I encounter.

This is **the first reason we learn algorithms**. <br/>

***Note:*** Some tech giants like Google, Facebook, Amazon, ask a lot of algorithmic questions, much more than technology-specific questions, in interviews. (Quote from Dr. Hazem Said, PhD. ASU University)

**Are there other reasons?** <br/>
Yes.
Learning algorithms also makes us better at **simple problem solving**, we get a wider spectrum of solutions when we learn the tools in algorithms and data structurs like Dynamic Programming, Stacks & Queues, etc.


## The most important thing to learn from algorithms

Learning HOW to construct famous algorithms is a good exercise, but, contrary to popular belief, it's ***NOT*the most important thing to learn about algorithms**.

The most important thing to learn is ***WHEN*** and ***HOW*** to ***USE*** the famous algorithms and data structures.

Not all problems are covered by famous algorithms and data structures, so we also need to ***THINK*** in a way to develop algorithms, this is what we gain when we learn ***Algorithm Design Approaches***.

Some of them are:
- Brute force.
- Greedy.
- Divide And Conquer.
- Dynamic Programming.
- Iterative Improvement.
- Backtracking.
- Branch & Bound.
- Space and time tradeoffs.

**So, to be an awesome software engineer through learning algorithms and data structures, focus on learning** <br/>
- **How** and **When** to **Use** famous algorithms and data structures.
-  How to **Think** to create an algorithm using *Algorithm Design Approaches*.

## CS Fields with advances in algorithms
- Basic algorithms in machine learning.
- Parallelization of known algorithms.
- Security algorithms, especially with the introduction of IoT.
- Simulation of large systems.
- Blockchain.

## Algorithms that changed CS world
- Search Engine Indexing, the algorithm that's behind Google.
- Public/Private Key.
- Forward error correction, transferring high quality codes on noisy channels.
- Pattern recognition and Machine Learning.
- Data compression, compressing things into mp3, mp4, all of that.
- Digital signature.

## Currently unsolved problems and algorithms
There are new terms, that we'll see, keep these abbreviations in mind: P (Polynomial), N(Non-deterministic)
- P problems: problems that:
    + can be solved in polynomial time.
    + the solution can be checked in polynomial time.

- NP problems: problems that:
    + can't be solved in polynomial time. (So far no efficient algorithms are found for them)
    + but, any solutions found (by any algorithm) can be checked in polynomial time.
- NP-Complete problems: a subset of NP problems that are equivalet to each other i.e. if you solve one of them, your algorithm can be used to solve all of them. (No efficient solutions are found yet), some NP-complete problems are:
    + Satisfiability problem.
    + Hamiltonian cycle problem.
    + Independent set problem.
    + Vertex cover problem.
All of these problems are completely different, but if an efficient algorithm is found for one of them, it can be used for all of them.

## The future of algorithms
In the last 20 years, a huge paradigm shift has been introduced to algorithms:
- The invention of Quantum Computers: A quantum register can hold all the possible values together, because of a fancy property in Quantum Mechanics called Superposition. (But the problem is that this superposition collapses to one of these values randomly whenever we see what the value the register holds).
- Shor's Algorithm: An algorithm that can solve Factorization Problem in polynomial time, using Quantum Computers (The Public/Private key algorithm is threatened since it's based on that problem), that started a butterfly effect, some of its effects are:
    + Quantum Cryptography is also ongoing.
    + A race between tech giants on Quantum Computers is ongoing, the major players are Google, IBM, Microsoft, D-Wave.
    + IBM also have its Quantum Computers online, we can program them! (We need to learn how to program them first xD)

## Can a computer solve ANY problem?
Alan Turing, the Einstein of CS, proved mathematically that there are some problems that a computer will **never** be able to solve. (Search for the Halting Problem, a problem that will never be solved by any computer whatsoever)

This is a theoretical proof, so it's not about computational power or whatever, it's about the nature of a computer, the operation and functions of a device that we call "*computer*".

## Unanswered questions in CS
These questions are so important that there is a *1 MILLION DOLLAR prize* for solving EACH question.
- Are P-problems the same as NP-problems?
    + If we proved that **yes, P == NP**, then all NP problems can be solved someday.
    + If we proved that **no, P != NP**, then at least SOME of them will NEVER be solved.